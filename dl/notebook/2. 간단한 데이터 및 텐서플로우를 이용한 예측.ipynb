{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. 간단한 데이터 및 텐서플로우를 이용한 예측.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP52R79JrjwM",
        "colab_type": "text"
      },
      "source": [
        "# 목표\n",
        "\n",
        "- BMI 지수 = (몸무게 / 키) * 키\n",
        "- BMI를 이용하여 비만도를 측정\n",
        "- 알고리즘 SVM을 이용하여 BMI를 학습, 비만도 판정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9ZnYgvwsJFo",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 획득"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw2Ab0Fcxxft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqhO13WXx0aG",
        "colab_type": "code",
        "outputId": "6facb7d7-73eb-4a22-db5e-81febbf9d3da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "df = pd.read_csv('3_bmi.csv')\n",
        "df.head(2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>178</td>\n",
              "      <td>69</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>190</td>\n",
              "      <td>62</td>\n",
              "      <td>thin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   height  weight   label\n",
              "0     178      69  normal\n",
              "1     190      62    thin"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcben60VsLC5",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 준비\n",
        "- 품질 향상"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5bYTWDx0fF",
        "colab_type": "code",
        "outputId": "92965d9c-713c-406b-d876-38c6520275a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df.shape, df.columns, df['label'].unique()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000, 3),\n",
              " Index(['height', 'weight', 'label'], dtype='object'),\n",
              " array(['normal', 'thin', 'fat'], dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqPpadYazXxM",
        "colab_type": "code",
        "outputId": "9c938d53-b00d-46e0-c10a-51743bf58367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "height     int64\n",
              "weight     int64\n",
              "label     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0qcxMlGyuVk",
        "colab_type": "code",
        "outputId": "a4221379-f7ab-4222-dd27-d419a744f6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df['height'].max(), df['height'].min(), df['weight'].max(), df['weight'].min()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 120, 80, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-x8jOigyuZC",
        "colab_type": "code",
        "outputId": "52c9b418-9403-4b4c-c2d8-642848e84eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# 데이터 정규화 -> 무게, 키의 최대치를 기준으로 처리\n",
        "# 처리된 값을 다시 해당 컬럼에 대입\n",
        "\n",
        "df['height'] = df['height'] / df['height'].max()\n",
        "df['weight'] = df['weight'] / df['weight'].max()\n",
        "df.head(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.89</td>\n",
              "      <td>0.8625</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.95</td>\n",
              "      <td>0.7750</td>\n",
              "      <td>thin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   height  weight   label\n",
              "0    0.89  0.8625  normal\n",
              "1    0.95  0.7750    thin"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcT6yJ1R07Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label은 종속변수. 분류를 벡터화해서 처리\n",
        "# 케이스 총 3개\n",
        "# thin->[1, 0, 0] / normal->[0, 1, 0] / fat->[0, 0, 1]\n",
        "df['label'] = df['label'].apply(lambda x : {'thin':np.array([1,0,0]), 'normal':np.array([0,1,0]), 'fat':np.array([0,0,1])}[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgJ7TSH55K3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 분류\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyuKWI885Vx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[['height', 'weight']], df['label'], test_size=0.25, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqYek3M8sykH",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 분석\n",
        "- 생략"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSSrw-aOtUhD",
        "colab_type": "text"
      },
      "source": [
        "# 머신러닝 모델링(딥러닝, 텐서플로우 사용)\n",
        " - 퍼셉트론\n",
        " - 각각의 출력값에 대해 가중치 계산, 바이어스(편향, 조정한 값)를 더해서 softmax라는 함수로 적용\n",
        " - 해당 이론을 수식으로 정리하여 함수로 표현\n",
        " - y = softmax(Wx + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj8O9jIWEdWq",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 플로우 그래프 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39_YTd2-yucb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "302fb8ce-5dd7-4261-d505-138cd0026328"
      },
      "source": [
        "import tensorflow as tf\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WgchHzbyugE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 텐서플로우로 수식 구현\n",
        "# input(x): 키, 몸무게\n",
        "x = tf.placeholder(tf.float32, [None,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TFzj1UmEUuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 가중치: shape 고려\n",
        "W = tf.Variable(tf.zeros([2,3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duLuB8bsGSYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b(bias): 편향값\n",
        "b = tf.Variable(tf.zeros([3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-iPEU6FFBb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 플로우 그래프: y = softmax(Wx+b)\n",
        "# x: matrix, 2차 행렬, [none, 2]\n",
        "# 행렬의 곱 (none, 2) * (2, 3) -> (none, 3)\n",
        "# bias값은 브로드캐스팅에 의해 stretch 되어 연산\n",
        "y = tf.nn.softmax(tf.matmul(x,W)+b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElNF1fmyHe_y",
        "colab_type": "code",
        "outputId": "e27f7967-b685-4567-a379-414a7c9259a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "f'{x.shape} X {W.shape} + {b.shape} = {y.shape}'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(?, 2) X (2, 3) + (3,) = (?, 3)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDOgxizSEnhk",
        "colab_type": "text"
      },
      "source": [
        "## 학습에 필요한 데이터 플로우 그래프 추가\n",
        "\n",
        "- 좋은 모델을 만들기 위한 장치\n",
        "  - 비용(cost), 손실(loss) 등의 값들이 원하는 결과에서 얼마나 떨어져 있는가를 판단/ 이 값들을 줄이는 방향으로 전개\n",
        "  - 이런 처리를 위해서 '크로스 엔트로피'와 같은 알고리즘 적용\n",
        "  - 정보 이론 분야의 정보 압축 알고리즘으로 고안되었음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRVIbTYJJiCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f76b813f-47b6-45bd-ee39-127b86b46b32"
      },
      "source": [
        "from IPython.display import Image\n",
        "# 크로스 엔트로피 함수\n",
        "Image('/content/sm4.png', width=300)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAABeCAYAAAAwuCPaAAAMKGlDQ1BJQ0MgUHJvZmlsZQAASImV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\nGoH/ABNnT8SVli6dAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 300
            }
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0MpY-zqJ7CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_: 정답 label\n",
        "# y : 예측 label\n",
        "# y_ = [1,0,0], [0,1,0], [0,0,1] => [None, 3]\n",
        "y_ = tf.placeholder(tf.float32, [None,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax43tGDoKfQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 크로스 엔트로피를 구성\n",
        "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7USLl5vPK9Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 크로스 엔트로피가 최소화 되도록 작업을 진행\n",
        "# 경사 하강법(Gradient descent algorithm)으로 수행\n",
        "# 텐서플로우가 변수의 비용을 줄이는 방향으로 조금씩 이동시켜서 연산 수행 => 비용과 손실, 오차율이 최소가 되게끔\n",
        "# 하이퍼파라미터는 일단 0.01 적용\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9yRIUR-K9Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 훈련 정의\n",
        "train = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4GpdOUuK9Ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정답률 예측 정의\n",
        "# tf.argmax(y,1): 모델이 각 데이터별로 적합하다고 판단하는 레이블 값을 취함\n",
        "predict = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsL80WVlK87h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정확도\n",
        "accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSglVTxjO1_i",
        "colab_type": "text"
      },
      "source": [
        "## 세션 가동 및 실행\n",
        "\n",
        "- 데이터를 증가시키면서 반복 학습 방법\n",
        "  1. 0\\~100, 0\\~200, ... 데이터의 전체 양 증가\n",
        "  2. 0\\~100, 100\\~200, ... 데이터의 양 고정, 횟수만 증가\n",
        "  - 횟수 증가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKpifjIIK8yU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "f57d5c7f-3a9b-4126-b90a-fc80f30952ff"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  # 1. 변수(조건) 초기화\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  # 2. 훈련 데이터를 나누기 위한 기준값 정의\n",
        "  # 2-1. 훈련 한번 수행시 데이터 크기\n",
        "  TRAIN_TERM = 100\n",
        "  # 2-2. 훈련 진행 횟수\n",
        "  train_count = int(X_train.shape[0] / TRAIN_TERM)\n",
        "  \n",
        "  # 3. 반복 학습 수행\n",
        "  for step in range(train_count):\n",
        "    # 3-1. 훈련데이터에서 데이터를 순차적으로 추출\n",
        "    offset = step * TRAIN_TERM\n",
        "    # datas = X_train[offset : offset + TRAIN_TERM]\n",
        "    # 3-2. 학습\n",
        "    # 학습 데이터 준비: 플레이스홀더에 값 채우기\n",
        "    # 테스트 데이터와 학습 데이터의 피쳐 순서 맞춰야 함\n",
        "    fd = {x:X_train[offset : offset + TRAIN_TERM], y_:list(y_train[offset : offset + TRAIN_TERM])}\n",
        "    # 학습 수행\n",
        "    sess.run(train, feed_dict=fd)\n",
        "    # 중간 확인\n",
        "    if step%10 == 0:\n",
        "      # 크로스 엔트로피 값 획득\n",
        "      cross_en = sess.run(cross_entropy, feed_dict=fd)\n",
        "      # 정확도 획득: 테스트 데이터와 데스트 데이터의 답을 주입\n",
        "      acc = sess.run(accuracy, feed_dict={x:X_test, y_:list(y_test)})\n",
        "      \n",
        "      print(f'step={step}, cross={cross_en}, acc={acc}')\n",
        "  acc = sess.run(accuracy, feed_dict={x:X_test, y_:list(y_test)})\n",
        "  print(f'마지막 횟수의 정확도={acc}') \n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step=0, cross=106.28909301757812, acc=0.37880000472068787\n",
            "step=10, cross=101.96707153320312, acc=0.5339999794960022\n",
            "step=20, cross=100.24037170410156, acc=0.682200014591217\n",
            "step=30, cross=94.66569519042969, acc=0.6797999739646912\n",
            "step=40, cross=93.02731323242188, acc=0.6715999841690063\n",
            "step=50, cross=91.35393524169922, acc=0.6862000226974487\n",
            "step=60, cross=81.40003967285156, acc=0.6728000044822693\n",
            "step=70, cross=84.91597747802734, acc=0.7228000164031982\n",
            "step=80, cross=84.13021087646484, acc=0.6949999928474426\n",
            "step=90, cross=81.22965240478516, acc=0.6832000017166138\n",
            "step=100, cross=78.5992431640625, acc=0.7426000237464905\n",
            "step=110, cross=78.42161560058594, acc=0.6772000193595886\n",
            "step=120, cross=75.88557434082031, acc=0.70660001039505\n",
            "step=130, cross=77.74769592285156, acc=0.6844000220298767\n",
            "step=140, cross=68.8153076171875, acc=0.6913999915122986\n",
            "마지막 횟수의 정확도=0.7455999851226807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9-AQrWst56c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64a68eb7-3c90-4169-8e5a-16e50455410b"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  TRAIN_TERM = 100\n",
        "  train_count = int(X_train.shape[0] / TRAIN_TERM)\n",
        "  # 훈련 횟수 증가\n",
        "  STEP_SEGMENT = 2*2*2*2\n",
        "  for step in range(train_count*STEP_SEGMENT):\n",
        "    offset = int(step * TRAIN_TERM / STEP_SEGMENT)\n",
        "    fd = {x:X_train[offset : offset + TRAIN_TERM], y_:list(y_train[offset : offset + TRAIN_TERM])}\n",
        "    sess.run(train, feed_dict=fd)\n",
        "    if step%STEP_SEGMENT == 0:\n",
        "      cross_en = sess.run(cross_entropy, feed_dict=fd)\n",
        "      acc = sess.run(accuracy, feed_dict={x:X_test, y_:list(y_test)})\n",
        "      print(f'step={step}, cross={cross_en}, acc={acc}')\n",
        "  acc = sess.run(accuracy, feed_dict={x:X_test, y_:list(y_test)})\n",
        "  print(f'마지막 횟수의 정확도={acc}') "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step=0, cross=106.28909301757812, acc=0.37880000472068787\n",
            "step=16, cross=97.68382263183594, acc=0.40459999442100525\n",
            "step=32, cross=94.61579895019531, acc=0.6230000257492065\n",
            "step=48, cross=91.69449615478516, acc=0.7016000151634216\n",
            "step=64, cross=87.54940795898438, acc=0.718999981880188\n",
            "step=80, cross=81.4825210571289, acc=0.8050000071525574\n",
            "step=96, cross=81.07170104980469, acc=0.6610000133514404\n",
            "step=112, cross=78.85374450683594, acc=0.753600001335144\n",
            "step=128, cross=73.00946044921875, acc=0.7486000061035156\n",
            "step=144, cross=75.01828002929688, acc=0.8180000185966492\n",
            "step=160, cross=68.12228393554688, acc=0.6909999847412109\n",
            "step=176, cross=62.46381759643555, acc=0.6827999949455261\n",
            "step=192, cross=65.49154663085938, acc=0.6866000294685364\n",
            "step=208, cross=67.22737884521484, acc=0.7401999831199646\n",
            "step=224, cross=64.77497100830078, acc=0.7441999912261963\n",
            "step=240, cross=65.12562561035156, acc=0.84579998254776\n",
            "step=256, cross=68.32593536376953, acc=0.8619999885559082\n",
            "step=272, cross=62.622196197509766, acc=0.7408000230789185\n",
            "step=288, cross=53.811134338378906, acc=0.7003999948501587\n",
            "step=304, cross=59.38344192504883, acc=0.7749999761581421\n",
            "step=320, cross=61.36271667480469, acc=0.8149999976158142\n",
            "step=336, cross=60.89073944091797, acc=0.8784000277519226\n",
            "step=352, cross=59.502784729003906, acc=0.8822000026702881\n",
            "step=368, cross=60.58372497558594, acc=0.8654000163078308\n",
            "step=384, cross=54.07996368408203, acc=0.8677999973297119\n",
            "step=400, cross=55.819664001464844, acc=0.8086000084877014\n",
            "step=416, cross=57.8330192565918, acc=0.8924000263214111\n",
            "step=432, cross=55.281394958496094, acc=0.8532000184059143\n",
            "step=448, cross=52.920936584472656, acc=0.7788000106811523\n",
            "step=464, cross=51.30915069580078, acc=0.7766000032424927\n",
            "step=480, cross=51.642173767089844, acc=0.8813999891281128\n",
            "step=496, cross=50.18199157714844, acc=0.8158000111579895\n",
            "step=512, cross=49.67838668823242, acc=0.8234000205993652\n",
            "step=528, cross=51.51053237915039, acc=0.8276000022888184\n",
            "step=544, cross=49.864688873291016, acc=0.8100000023841858\n",
            "step=560, cross=48.514461517333984, acc=0.8259999752044678\n",
            "step=576, cross=51.2484130859375, acc=0.8974000215530396\n",
            "step=592, cross=46.80726623535156, acc=0.8145999908447266\n",
            "step=608, cross=51.7081298828125, acc=0.8578000068664551\n",
            "step=624, cross=48.02537155151367, acc=0.8507999777793884\n",
            "step=640, cross=51.68503189086914, acc=0.8596000075340271\n",
            "step=656, cross=49.10090637207031, acc=0.8695999979972839\n",
            "step=672, cross=49.41439437866211, acc=0.8547999858856201\n",
            "step=688, cross=47.326114654541016, acc=0.8988000154495239\n",
            "step=704, cross=50.41569137573242, acc=0.9049999713897705\n",
            "step=720, cross=44.0017204284668, acc=0.8830000162124634\n",
            "step=736, cross=41.438899993896484, acc=0.8885999917984009\n",
            "step=752, cross=44.401512145996094, acc=0.8461999893188477\n",
            "step=768, cross=52.40028762817383, acc=0.8809999823570251\n",
            "step=784, cross=46.948158264160156, acc=0.8985999822616577\n",
            "step=800, cross=52.11923599243164, acc=0.9046000242233276\n",
            "step=816, cross=42.565643310546875, acc=0.8726000189781189\n",
            "step=832, cross=42.3279914855957, acc=0.892799973487854\n",
            "step=848, cross=44.9755859375, acc=0.8510000109672546\n",
            "step=864, cross=46.18117904663086, acc=0.9067999720573425\n",
            "step=880, cross=43.33404541015625, acc=0.854200005531311\n",
            "step=896, cross=48.95998001098633, acc=0.8960000276565552\n",
            "step=912, cross=39.76697540283203, acc=0.8586000204086304\n",
            "step=928, cross=42.8490104675293, acc=0.9156000018119812\n",
            "step=944, cross=38.33820724487305, acc=0.8575999736785889\n",
            "step=960, cross=38.203392028808594, acc=0.8532000184059143\n",
            "step=976, cross=37.88380432128906, acc=0.8561999797821045\n",
            "step=992, cross=43.413875579833984, acc=0.9133999943733215\n",
            "step=1008, cross=36.15522384643555, acc=0.8727999925613403\n",
            "step=1024, cross=41.37648010253906, acc=0.8988000154495239\n",
            "step=1040, cross=39.79689025878906, acc=0.9154000282287598\n",
            "step=1056, cross=41.09074783325195, acc=0.8998000025749207\n",
            "step=1072, cross=41.43324661254883, acc=0.9160000085830688\n",
            "step=1088, cross=39.822513580322266, acc=0.8944000005722046\n",
            "step=1104, cross=43.13251876831055, acc=0.8708000183105469\n",
            "step=1120, cross=40.978965759277344, acc=0.9083999991416931\n",
            "step=1136, cross=40.79502487182617, acc=0.923799991607666\n",
            "step=1152, cross=40.842777252197266, acc=0.9150000214576721\n",
            "step=1168, cross=42.524776458740234, acc=0.9200000166893005\n",
            "step=1184, cross=38.227569580078125, acc=0.8898000121116638\n",
            "step=1200, cross=34.89888381958008, acc=0.8069999814033508\n",
            "step=1216, cross=43.6605110168457, acc=0.925599992275238\n",
            "step=1232, cross=41.74529266357422, acc=0.9229999780654907\n",
            "step=1248, cross=39.35427474975586, acc=0.9003999829292297\n",
            "step=1264, cross=32.63231658935547, acc=0.8393999934196472\n",
            "step=1280, cross=41.321533203125, acc=0.9277999997138977\n",
            "step=1296, cross=31.930282592773438, acc=0.8259999752044678\n",
            "step=1312, cross=47.70686721801758, acc=0.9265999794006348\n",
            "step=1328, cross=39.93467712402344, acc=0.9085999727249146\n",
            "step=1344, cross=34.39252471923828, acc=0.9296000003814697\n",
            "step=1360, cross=39.4623908996582, acc=0.9247999787330627\n",
            "step=1376, cross=40.875022888183594, acc=0.9085999727249146\n",
            "step=1392, cross=35.714881896972656, acc=0.9211999773979187\n",
            "step=1408, cross=38.53984069824219, acc=0.930400013923645\n",
            "step=1424, cross=38.07854461669922, acc=0.9277999997138977\n",
            "step=1440, cross=40.022159576416016, acc=0.8939999938011169\n",
            "step=1456, cross=38.217220306396484, acc=0.9341999888420105\n",
            "step=1472, cross=38.731201171875, acc=0.932200014591217\n",
            "step=1488, cross=39.98661804199219, acc=0.9345999956130981\n",
            "step=1504, cross=38.53780746459961, acc=0.9277999997138977\n",
            "step=1520, cross=36.031673431396484, acc=0.9190000295639038\n",
            "step=1536, cross=33.72659683227539, acc=0.871999979019165\n",
            "step=1552, cross=34.92503356933594, acc=0.9358000159263611\n",
            "step=1568, cross=40.23165512084961, acc=0.9215999841690063\n",
            "step=1584, cross=38.89208221435547, acc=0.9412000179290771\n",
            "step=1600, cross=34.83378982543945, acc=0.9399999976158142\n",
            "step=1616, cross=40.45524978637695, acc=0.9154000282287598\n",
            "step=1632, cross=36.11211395263672, acc=0.9085999727249146\n",
            "step=1648, cross=35.443603515625, acc=0.9151999950408936\n",
            "step=1664, cross=36.9466438293457, acc=0.942799985408783\n",
            "step=1680, cross=32.62356185913086, acc=0.9103999733924866\n",
            "step=1696, cross=36.88945770263672, acc=0.9399999976158142\n",
            "step=1712, cross=38.14209747314453, acc=0.9332000017166138\n",
            "step=1728, cross=32.059303283691406, acc=0.9381999969482422\n",
            "step=1744, cross=40.17557144165039, acc=0.9246000051498413\n",
            "step=1760, cross=36.4360466003418, acc=0.906000018119812\n",
            "step=1776, cross=37.348350524902344, acc=0.9355999827384949\n",
            "step=1792, cross=35.44008255004883, acc=0.9273999929428101\n",
            "step=1808, cross=36.0106086730957, acc=0.9233999848365784\n",
            "step=1824, cross=38.8541374206543, acc=0.9065999984741211\n",
            "step=1840, cross=34.00288391113281, acc=0.9297999739646912\n",
            "step=1856, cross=38.02155303955078, acc=0.9297999739646912\n",
            "step=1872, cross=35.096412658691406, acc=0.9405999779701233\n",
            "step=1888, cross=36.63945007324219, acc=0.9444000124931335\n",
            "step=1904, cross=35.888648986816406, acc=0.9115999937057495\n",
            "step=1920, cross=33.47871017456055, acc=0.9398000240325928\n",
            "step=1936, cross=37.663265228271484, acc=0.942799985408783\n",
            "step=1952, cross=36.92215347290039, acc=0.9508000016212463\n",
            "step=1968, cross=35.381080627441406, acc=0.9488000273704529\n",
            "step=1984, cross=30.44963836669922, acc=0.9516000151634216\n",
            "step=2000, cross=34.48611831665039, acc=0.9373999834060669\n",
            "step=2016, cross=32.621482849121094, acc=0.9416000247001648\n",
            "step=2032, cross=32.45987319946289, acc=0.9394000172615051\n",
            "step=2048, cross=30.65059471130371, acc=0.9517999887466431\n",
            "step=2064, cross=31.461999893188477, acc=0.9453999996185303\n",
            "step=2080, cross=37.00154495239258, acc=0.9354000091552734\n",
            "step=2096, cross=31.78546714782715, acc=0.9430000185966492\n",
            "step=2112, cross=30.102680206298828, acc=0.9174000024795532\n",
            "step=2128, cross=31.35517120361328, acc=0.9359999895095825\n",
            "step=2144, cross=30.76434898376465, acc=0.9261999726295471\n",
            "step=2160, cross=33.175865173339844, acc=0.949400007724762\n",
            "step=2176, cross=35.75713348388672, acc=0.954200029373169\n",
            "step=2192, cross=31.574085235595703, acc=0.9502000212669373\n",
            "step=2208, cross=31.9493408203125, acc=0.9517999887466431\n",
            "step=2224, cross=31.16037940979004, acc=0.9300000071525574\n",
            "step=2240, cross=30.202102661132812, acc=0.9186000227928162\n",
            "step=2256, cross=30.237316131591797, acc=0.9521999955177307\n",
            "step=2272, cross=31.845823287963867, acc=0.9218000173568726\n",
            "step=2288, cross=37.6999397277832, acc=0.9412000179290771\n",
            "step=2304, cross=31.01079559326172, acc=0.9458000063896179\n",
            "step=2320, cross=33.461280822753906, acc=0.942799985408783\n",
            "step=2336, cross=28.54561424255371, acc=0.909600019454956\n",
            "step=2352, cross=36.39753341674805, acc=0.9294000267982483\n",
            "step=2368, cross=28.77139663696289, acc=0.9476000070571899\n",
            "step=2384, cross=28.663270950317383, acc=0.9527999758720398\n",
            "마지막 횟수의 정확도=0.9344000220298767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N0iSn7GzV87",
        "colab_type": "text"
      },
      "source": [
        "# 텐서보드\n",
        "\n",
        "- 목적: 텐서보드를 이용하여 그래프(데이터 흐름)를 시각적으로 확인\n",
        "- 방법(코드적으로 조금 다름)\n",
        "  1. 로컬 PC에서 수행\n",
        "  2. colab에서 수행\n",
        "  * 데이터가 누적되기 때문에 클리어 후 처리해야 정확하게 나옴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6e6sO6s0oqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 텐서보드를 위해서 추가된 코드(colab)\n",
        "from tensorboardcolab import * \n",
        "import shutil, os\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNkWdq-7yLup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78790960-f7c0-4df9-f4d2-4554cdc48b22"
      },
      "source": [
        "# 텐서 데이터 플로우 구현\n",
        "x             = tf.placeholder( tf.float32, [None,2] )\n",
        "y_            = tf.placeholder( tf.float32, [None, 3] )        # 정답\n",
        "\n",
        "with tf.name_scope('interface') as scope:\n",
        "  W             = tf.Variable( tf.zeros([2, 3]) ) \n",
        "  b             = tf.Variable( tf.zeros([3]) )\n",
        "  with tf.name_scope('activation') as scope:\n",
        "\t  y  = tf.nn.softmax(tf.matmul(x,W) + b)      # 간단한 입력->출력층구성\n",
        "\n",
        "with tf.name_scope('loss') as scope:\n",
        "\tcross_entropy = -tf.reduce_sum( y_ * tf.log(y) )               # 크로스엔트로피\n",
        "\n",
        "with tf.name_scope('train') as scope:\n",
        "\toptimazer     = tf.train.GradientDescentOptimizer(0.01)        # 경사하강법\n",
        "\ttrain         = optimazer.minimize( cross_entropy )            # 훈련\n",
        "\n",
        "with tf.name_scope('accuracy') as scope:\n",
        "  predict       = tf.equal( tf.argmax(y, 1), tf.argmax(y_, 1) )  # 예측\n",
        "  accuracy      = tf.reduce_mean( tf.cast(predict, tf.float32) ) # 평가\n",
        "\n",
        "# 텐서보드를 위해서 추가된 코드(코렙에서 사용하는 스타일) --------------------\n",
        "from tensorboardcolab import *\n",
        "import shutil, os\n",
        "# 디렉토리 및 그 이하 파일가지 삭제, 에러나면 무시\n",
        "shutil.rmtree('./Graph', ignore_errors=True) \n",
        "# 디렉토리 생성\n",
        "os.mkdir('./Graph')\n",
        "# 기존의 tf에 만들어진 요소들 초기화 처리(에러가 날수도 있다)\n",
        "# tf.reset_default_graph()\n",
        "# 텐서보드 객체 생성\n",
        "tbc = TensorBoardColab()\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "# 실행을 통한 학습,예측처리\n",
        "with tf.Session() as sess:\n",
        "  sess.run( tf.global_variables_initializer() )\n",
        "  TRAIN_TERM = 100  \n",
        "  train_count = int(X_train.shape[0] / TRAIN_TERM)  \n",
        "  STEP_SEGMENT = 2*2*2*2\n",
        "  for step in range(train_count*STEP_SEGMENT): # step:(0~149)    \n",
        "    offset = int(step*TRAIN_TERM / STEP_SEGMENT)\n",
        "    fd = {x:X_train[offset : offset + TRAIN_TERM], y_:list(y_train[offset : offset + TRAIN_TERM])}\n",
        "    sess.run( train, feed_dict=fd )\n",
        "    if step%STEP_SEGMENT == 0:\n",
        "      cross_en = sess.run( cross_entropy, feed_dict=fd )\n",
        "      acc      = sess.run( accuracy, feed_dict={x:X_test, y_:list(y_test)} )\n",
        "      print(f'step={step}, cross={cross_en}, acc={acc}')\n",
        "  acc = sess.run( accuracy, feed_dict={x:X_test, y_:list(y_test)} )\n",
        "  print( f'정확도: {acc}')\n",
        "  # 코렙 텐서보드의 물리적위치에 그래프를 기록한다 ----------------------\n",
        "  writer = tbc.get_writer()\n",
        "  writer.add_graph( sess.graph ) # 그래프 추가=\n",
        "  writer.flush() # 강제로 전송\n",
        "  # ---------------------------------------------------------------------\n",
        "\n",
        "# 텐서보드를 닫는다 \n",
        "tbc.close()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://ad331172.ngrok.io\n",
            "step=0, cross=106.28909301757812, acc=0.37880000472068787\n",
            "step=16, cross=97.68382263183594, acc=0.40459999442100525\n",
            "step=32, cross=94.61579895019531, acc=0.6230000257492065\n",
            "step=48, cross=91.69449615478516, acc=0.7016000151634216\n",
            "step=64, cross=87.54940795898438, acc=0.718999981880188\n",
            "step=80, cross=81.4825210571289, acc=0.8050000071525574\n",
            "step=96, cross=81.07170104980469, acc=0.6610000133514404\n",
            "step=112, cross=78.85374450683594, acc=0.753600001335144\n",
            "step=128, cross=73.00946044921875, acc=0.7486000061035156\n",
            "step=144, cross=75.01828002929688, acc=0.8180000185966492\n",
            "step=160, cross=68.12228393554688, acc=0.6909999847412109\n",
            "step=176, cross=62.46381759643555, acc=0.6827999949455261\n",
            "step=192, cross=65.49154663085938, acc=0.6866000294685364\n",
            "step=208, cross=67.22737884521484, acc=0.7401999831199646\n",
            "step=224, cross=64.77497100830078, acc=0.7441999912261963\n",
            "step=240, cross=65.12562561035156, acc=0.84579998254776\n",
            "step=256, cross=68.32593536376953, acc=0.8619999885559082\n",
            "step=272, cross=62.622196197509766, acc=0.7408000230789185\n",
            "step=288, cross=53.811134338378906, acc=0.7003999948501587\n",
            "step=304, cross=59.38344192504883, acc=0.7749999761581421\n",
            "step=320, cross=61.36271667480469, acc=0.8149999976158142\n",
            "step=336, cross=60.89073944091797, acc=0.8784000277519226\n",
            "step=352, cross=59.502784729003906, acc=0.8822000026702881\n",
            "step=368, cross=60.58372497558594, acc=0.8654000163078308\n",
            "step=384, cross=54.07996368408203, acc=0.8677999973297119\n",
            "step=400, cross=55.819664001464844, acc=0.8086000084877014\n",
            "step=416, cross=57.8330192565918, acc=0.8924000263214111\n",
            "step=432, cross=55.281394958496094, acc=0.8532000184059143\n",
            "step=448, cross=52.920936584472656, acc=0.7788000106811523\n",
            "step=464, cross=51.30915069580078, acc=0.7766000032424927\n",
            "step=480, cross=51.642173767089844, acc=0.8813999891281128\n",
            "step=496, cross=50.18199157714844, acc=0.8158000111579895\n",
            "step=512, cross=49.67838668823242, acc=0.8234000205993652\n",
            "step=528, cross=51.51053237915039, acc=0.8276000022888184\n",
            "step=544, cross=49.864688873291016, acc=0.8100000023841858\n",
            "step=560, cross=48.514461517333984, acc=0.8259999752044678\n",
            "step=576, cross=51.2484130859375, acc=0.8974000215530396\n",
            "step=592, cross=46.80726623535156, acc=0.8145999908447266\n",
            "step=608, cross=51.7081298828125, acc=0.8578000068664551\n",
            "step=624, cross=48.02537155151367, acc=0.8507999777793884\n",
            "step=640, cross=51.68503189086914, acc=0.8596000075340271\n",
            "step=656, cross=49.10090637207031, acc=0.8695999979972839\n",
            "step=672, cross=49.41439437866211, acc=0.8547999858856201\n",
            "step=688, cross=47.326114654541016, acc=0.8988000154495239\n",
            "step=704, cross=50.41569137573242, acc=0.9049999713897705\n",
            "step=720, cross=44.0017204284668, acc=0.8830000162124634\n",
            "step=736, cross=41.438899993896484, acc=0.8885999917984009\n",
            "step=752, cross=44.401512145996094, acc=0.8461999893188477\n",
            "step=768, cross=52.40028762817383, acc=0.8809999823570251\n",
            "step=784, cross=46.948158264160156, acc=0.8985999822616577\n",
            "step=800, cross=52.11923599243164, acc=0.9046000242233276\n",
            "step=816, cross=42.565643310546875, acc=0.8726000189781189\n",
            "step=832, cross=42.3279914855957, acc=0.892799973487854\n",
            "step=848, cross=44.9755859375, acc=0.8510000109672546\n",
            "step=864, cross=46.18117904663086, acc=0.9067999720573425\n",
            "step=880, cross=43.33404541015625, acc=0.854200005531311\n",
            "step=896, cross=48.95998001098633, acc=0.8960000276565552\n",
            "step=912, cross=39.76697540283203, acc=0.8586000204086304\n",
            "step=928, cross=42.8490104675293, acc=0.9156000018119812\n",
            "step=944, cross=38.33820724487305, acc=0.8575999736785889\n",
            "step=960, cross=38.203392028808594, acc=0.8532000184059143\n",
            "step=976, cross=37.88380432128906, acc=0.8561999797821045\n",
            "step=992, cross=43.413875579833984, acc=0.9133999943733215\n",
            "step=1008, cross=36.15522384643555, acc=0.8727999925613403\n",
            "step=1024, cross=41.37648010253906, acc=0.8988000154495239\n",
            "step=1040, cross=39.79689025878906, acc=0.9154000282287598\n",
            "step=1056, cross=41.09074783325195, acc=0.8998000025749207\n",
            "step=1072, cross=41.43324661254883, acc=0.9160000085830688\n",
            "step=1088, cross=39.822513580322266, acc=0.8944000005722046\n",
            "step=1104, cross=43.13251876831055, acc=0.8708000183105469\n",
            "step=1120, cross=40.978965759277344, acc=0.9083999991416931\n",
            "step=1136, cross=40.79502487182617, acc=0.923799991607666\n",
            "step=1152, cross=40.842777252197266, acc=0.9150000214576721\n",
            "step=1168, cross=42.524776458740234, acc=0.9200000166893005\n",
            "step=1184, cross=38.227569580078125, acc=0.8898000121116638\n",
            "step=1200, cross=34.89888381958008, acc=0.8069999814033508\n",
            "step=1216, cross=43.6605110168457, acc=0.925599992275238\n",
            "step=1232, cross=41.74529266357422, acc=0.9229999780654907\n",
            "step=1248, cross=39.35427474975586, acc=0.9003999829292297\n",
            "step=1264, cross=32.63231658935547, acc=0.8393999934196472\n",
            "step=1280, cross=41.321533203125, acc=0.9277999997138977\n",
            "step=1296, cross=31.930282592773438, acc=0.8259999752044678\n",
            "step=1312, cross=47.70686721801758, acc=0.9265999794006348\n",
            "step=1328, cross=39.93467712402344, acc=0.9085999727249146\n",
            "step=1344, cross=34.39252471923828, acc=0.9296000003814697\n",
            "step=1360, cross=39.4623908996582, acc=0.9247999787330627\n",
            "step=1376, cross=40.875022888183594, acc=0.9085999727249146\n",
            "step=1392, cross=35.714881896972656, acc=0.9211999773979187\n",
            "step=1408, cross=38.53984069824219, acc=0.930400013923645\n",
            "step=1424, cross=38.07854461669922, acc=0.9277999997138977\n",
            "step=1440, cross=40.022159576416016, acc=0.8939999938011169\n",
            "step=1456, cross=38.217220306396484, acc=0.9341999888420105\n",
            "step=1472, cross=38.731201171875, acc=0.932200014591217\n",
            "step=1488, cross=39.98661804199219, acc=0.9345999956130981\n",
            "step=1504, cross=38.53780746459961, acc=0.9277999997138977\n",
            "step=1520, cross=36.031673431396484, acc=0.9190000295639038\n",
            "step=1536, cross=33.72659683227539, acc=0.871999979019165\n",
            "step=1552, cross=34.92503356933594, acc=0.9358000159263611\n",
            "step=1568, cross=40.23165512084961, acc=0.9215999841690063\n",
            "step=1584, cross=38.89208221435547, acc=0.9412000179290771\n",
            "step=1600, cross=34.83378982543945, acc=0.9399999976158142\n",
            "step=1616, cross=40.45524978637695, acc=0.9154000282287598\n",
            "step=1632, cross=36.11211395263672, acc=0.9085999727249146\n",
            "step=1648, cross=35.443603515625, acc=0.9151999950408936\n",
            "step=1664, cross=36.9466438293457, acc=0.942799985408783\n",
            "step=1680, cross=32.62356185913086, acc=0.9103999733924866\n",
            "step=1696, cross=36.88945770263672, acc=0.9399999976158142\n",
            "step=1712, cross=38.14209747314453, acc=0.9332000017166138\n",
            "step=1728, cross=32.059303283691406, acc=0.9381999969482422\n",
            "step=1744, cross=40.17557144165039, acc=0.9246000051498413\n",
            "step=1760, cross=36.4360466003418, acc=0.906000018119812\n",
            "step=1776, cross=37.348350524902344, acc=0.9355999827384949\n",
            "step=1792, cross=35.44008255004883, acc=0.9273999929428101\n",
            "step=1808, cross=36.0106086730957, acc=0.9233999848365784\n",
            "step=1824, cross=38.8541374206543, acc=0.9065999984741211\n",
            "step=1840, cross=34.00288391113281, acc=0.9297999739646912\n",
            "step=1856, cross=38.02155303955078, acc=0.9297999739646912\n",
            "step=1872, cross=35.096412658691406, acc=0.9405999779701233\n",
            "step=1888, cross=36.63945007324219, acc=0.9444000124931335\n",
            "step=1904, cross=35.888648986816406, acc=0.9115999937057495\n",
            "step=1920, cross=33.47871017456055, acc=0.9398000240325928\n",
            "step=1936, cross=37.663265228271484, acc=0.942799985408783\n",
            "step=1952, cross=36.92215347290039, acc=0.9508000016212463\n",
            "step=1968, cross=35.381080627441406, acc=0.9488000273704529\n",
            "step=1984, cross=30.44963836669922, acc=0.9516000151634216\n",
            "step=2000, cross=34.48611831665039, acc=0.9373999834060669\n",
            "step=2016, cross=32.621482849121094, acc=0.9416000247001648\n",
            "step=2032, cross=32.45987319946289, acc=0.9394000172615051\n",
            "step=2048, cross=30.65059471130371, acc=0.9517999887466431\n",
            "step=2064, cross=31.461999893188477, acc=0.9453999996185303\n",
            "step=2080, cross=37.00154495239258, acc=0.9354000091552734\n",
            "step=2096, cross=31.78546714782715, acc=0.9430000185966492\n",
            "step=2112, cross=30.102680206298828, acc=0.9174000024795532\n",
            "step=2128, cross=31.35517120361328, acc=0.9359999895095825\n",
            "step=2144, cross=30.76434898376465, acc=0.9261999726295471\n",
            "step=2160, cross=33.175865173339844, acc=0.949400007724762\n",
            "step=2176, cross=35.75713348388672, acc=0.954200029373169\n",
            "step=2192, cross=31.574085235595703, acc=0.9502000212669373\n",
            "step=2208, cross=31.9493408203125, acc=0.9517999887466431\n",
            "step=2224, cross=31.16037940979004, acc=0.9300000071525574\n",
            "step=2240, cross=30.202102661132812, acc=0.9186000227928162\n",
            "step=2256, cross=30.237316131591797, acc=0.9521999955177307\n",
            "step=2272, cross=31.845823287963867, acc=0.9218000173568726\n",
            "step=2288, cross=37.6999397277832, acc=0.9412000179290771\n",
            "step=2304, cross=31.01079559326172, acc=0.9458000063896179\n",
            "step=2320, cross=33.461280822753906, acc=0.942799985408783\n",
            "step=2336, cross=28.54561424255371, acc=0.909600019454956\n",
            "step=2352, cross=36.39753341674805, acc=0.9294000267982483\n",
            "step=2368, cross=28.77139663696289, acc=0.9476000070571899\n",
            "step=2384, cross=28.663270950317383, acc=0.9527999758720398\n",
            "정확도: 0.9344000220298767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4VqRPRWtWax",
        "colab_type": "text"
      },
      "source": [
        "# 시스템 통합\n",
        "- 산출물 skip"
      ]
    }
  ]
}