# ![]()CNN을 이용한 이미지 인식

- 시각 인지 과정
  - 계층적으로 일어난다
  - 눈의 앞층에 존재하는 세포들이 이미지의 극히 일부분만 인식
  - 이런 데이터들이 모여서 하나의 이미지로 인식
  - 뒤쪽에 있는 세포들은 더 큰 이미지를 인지
  - 시각 피질 내 여러 세포들은 각자 부분을 인지
    - 지형학적인 매핑 과정이 존재
- 1980년대 경사 하강법이 학습 가능한 합성곱 네트워크 기반으로 만든 LeNet모델에 성공적으로 적용되어서 숫자 코드 인식에 성공
- 2012년 AlexNet에서 최초 CNN모델을 적용하여 이것이 이미지 인식의 표준이 됨



## 이미지 데이터
- 수치로 구성
- shape
  1. 높이: 세로 픽셀 수
  2. 너비: 가로 픽셀 수
  3. 채널: 색의 성분
    - 흑백: 채널 1개, 픽셀 하나당 0~255(1 unsigned byte)
    - 컬러: 채널 3개, RGB
- 3D(cube, 3차 행렬)
  - [n개의 이미지, h, w, c(1 or 3)]
  - [n개의 이미지, c(1 or 3), h, w]
- Pillow 활용
  - 이미지를 화면에 보이게 처리하는 모듈
  - JPEG, BPM, GIF, PNG, PPM, TIFF 등 지원

```python
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

# 이미지 원본 로드
img = Image.open('/content/8.cnn_building.jpg')
```

![](C:\Users\admin\Documents\GitHub\pengsoo\dl\data\8.cnn_building.jpg)

## 이미지 확인

- 컬러, 흑백 비교

```python
# 컬러 이미지 배열화 처리
np.array(img).shape, img.size   # [h, w, c] 성립됨

# 흑백 이미지로 변환 확인
img = img.convert('L')
np.array(img).shape, img.size   # channel=1이면 생략됨
```



## 이미지를 텐서로 변환

- 이미지 원본 -> Image -> ndarray -> Tensor

```python
import torch

img_tensor = torch.Tensor(np.array(img))
```

* 커널의 값과 값의 배치에 의해서 이미지가 스트라이드 된 결과로 다양하게 이미지 변화시킴
* 이미지의 특징을 추출하는 것과 동일
* 커널의 공유 파라미터(=W)에 의해 특징을 다양하게 추출 가능

![](C:\Users\admin\Documents\GitHub\pengsoo\dl\data\8.합성곱연산_모서리탐지.jpeg)

------

- 이미지 원본 5 x 5 x 1(높이 x 가로 x 채널수)
- 커널(=필터)이 전체 이미지를 처음부터 끝까지 스캔(필터링, 특징 추출)
- 커널 크기: 3 x 3
- stride: 가로 1, 세로 1
- 커널이 이미지 원본을 스캔하는 총 횟수: 9
  - (5-3+1) x (5-3+1) = 9

$$
스캔 횟수 = {(image가로 - kernel가로 + stride) * (image세로 - kernel세로 + stride)}
$$

```python
tmp = np.array([ [13,1,2,3,4], [12,14,14,2,2], [1,0,16,12,1], [3,3,1,12,11], [2,2,4,2,13] ])
ex_img_tensor = torch.Tensor(tmp)

# 합성곱 연산 처리 함수
def convolution_op(image, kernel):
  height, width = image.size()
  kernel_size = kernel.size(0)
  # 합성곱 연산 결과를 담을 리스트
  tmp = list()
  for i in range(height - kernel_size + 1):
    tmp.append([ 
                torch.sum(image[i:i+kernel_size, j:j+kernel_size] * kernel) 
                for j in range(width - kernel_size + 1)
                ])
  convs = torch.Tensor(tmp)
  return convs  #컨볼루션 텐서를 반환
```

![](C:\Users\admin\Documents\GitHub\pengsoo\dl\data\img_binary.png)

```python
# 원본드로잉
fig, axes = plt.subplots(1,1)
axes.matshow(ex_img_tensor, cmap='binary')
plt.show()
```

![](C:\Users\admin\Documents\GitHub\pengsoo\dl\data\img_tensor.png)

```python
# 수직선 탐지 커널 (3,3)
vertical_kernel = torch.Tensor([ [1,0,-1], [1,0,-1], [1,0,-1] ])
# 수평선 탐지 커널 (3,3)
horizontal_kernel = torch.Tensor([ [1,1,1], [0,0,0], [-1,-1,-1] ])

v_convs = convolution_op(ex_img_tensor, vertical_kernel).view(3,3)
h_convs = convolution_op(ex_img_tensor, horizontal_kernel).view(3,3)

fig, (ax1, ax2) = plt.subplots(1,2)

ax1.matshow(np.array(v_convs), cmap='binary')
ax1.axis('off')
ax1.set_title('vertical kernel')

ax2.matshow(np.array(h_convs), cmap='binary')
ax2.axis('off')
ax2.set_title('horizontal kernel')
plt.show()
```

![](C:\Users\admin\Documents\GitHub\pengsoo\dl\data\img_tensor2.png)

```python
v_convs = convolution_op(img_tensor, vertical_kernel)
h_convs = convolution_op(img_tensor, horizontal_kernel)

fig, (ax1, ax2) = plt.subplots(1,2)

ax1.imshow(np.array(v_convs), cmap='binary')
ax1.axis('off')
ax1.set_title('vertical kernel')

ax2.imshow(np.array(h_convs), cmap='binary')
ax2.axis('off')
ax2.set_title('horizontal kernel')

plt.show()
```

<img src="C:\Users\admin\Documents\GitHub\pengsoo\dl\data\img_tensor3.png" alt="img_tensor3"  />

## 합성곱층

- B: 배치 사이즈, 이미지 개수

- C: 채널

- H: 이미지 높이

- W: 이미지 너비

- 출력 채널 개수만큼의 커널에 이미지 원본을 통과시킨다

- 하나의 이미지에 출력 채널 개수만큼 설명 내용이 발생

  ![](C:\Users\admin\Documents\GitHub\pengsoo\dl\data\8.이미지처리.jpeg)

### 공식

- K: 커널 크기
- S: 스트라이드
- P: 패딩

$$
H(W)_{out} = \frac{H(W)_{in} + 2*P - K}{S}+1
$$

- 원본이미지(타지마할)
  - ( (150 + 2 * 0 - 3) / 1 ) + 1 = 148

- 레이어 설계시 수치의 변화를 잘 계산해서 채널 수를 지정 => 채널의 값에 따라 성능이 달라짐



### 합성곱층 API & 직접 구현

- torch.nn.Conv2d

```python
h, w = img_tensor.size()
# 입력 데이터 이미지 준비
# shape 확장 => [batch, channel, h, w]
img_tensor = img_tensor.expand(1,1,h,w)

# 합성곱층을 만들기 위한 수치 정보 준비
batch, in_channels, height, weight = img_tensor.size()
out_channels = 1
kernel_size = 3
stride = 1

conv_layer = torch.nn.Conv2d(in_channels=in_channels, 
                             out_channels=out_channels, 
                             kernel_size=kernel_size, 
                             stride=stride,
                             bias=False)


# 합성곱 레이어 커널값(가중치, W, 공용 파라미터) 교체
# 이미 값이 설정되어있음(기본 설정, 난수)
# 자동으로 생성되는 커널의 shape이 4D이므로, 수직 커널도 확장 필요
conv_layer.weight.data = vertical_kernel.expand(1, 1, kernel_size, kernel_size)

```

- 기본 제공 API nn.Conv2d 함수가 조건들을 부여해 직접 만든 함수와 동일한 효과를 내는지 검증

```python
convs = conv_layer(img_tensor)
plt.imshow(convs.squeeze().detach().numpy(), cmap='gray')
plt.axis('off')
plt.show()
```

![](C:\Users\admin\Documents\GitHub\pengsoo\dl\data\img_tensor4.png)

```python
# relu 통과시켜서 음수 제거 -> 특성 강화
act_map = torch.relu(convs)
plt.imshow(act_map.squeeze().detach().numpy(), cmap='binary')
plt.axis('off')
plt.show()
```



## 풀링층

![](C:\Users\admin\Documents\GitHub\pengsoo\dl\data\8.pooling.jpeg)

![](C:\Users\admin\Documents\GitHub\pengsoo\dl\data\8.pooling2.jpeg)

### 풀링층 직접 구현

- 합성곱층을 통과한 활성화맵의 값(특징)을 강화
- 이미지의 크기를 줄여서 연산 속도를 높임

```python
b, c, h, w = act_map.size() # 이전 계층의 결과물
kernel_size = 2 # 커널 사이즈 설정

# 세 번째 차원의 인덱스 번호 2번에 대해 풀링 처리하고, 뒤에 stride를 추가한 형태
act_map.unfold(2, kernel_size, kernel_size).size()

# 이렇게 만들어진 텐서에서 추가된 부분에 최대값을 취함
# maxpool 완성
act_map.unfold(
        2, kernel_size, kernel_size).unfold(
        3, kernel_size, kernel_size).max(-1)[0].max(-1)[0].size()


# 실 구현
def maxpooling(x, kernel_size, stride=None):
  assert x.ndimension() == 4   # 4D만 지원
  if not stride:
    stride = kernel_size
  # 입력 데이터의 정보
  b, c, h, w = x.size()
  # maxpooling
  m = x.unfold(2, kernel_size, stride).unfold(3, kernel_size, stride).max(-1)[0].max(-1)[0]
  return m
```

### 풀링층 API
- torch.nn.MaxPool2d

```python
maxpool_layer = torch.nn.MaxPool2d(kernel_size=2, stride=2)
mps = maxpool_layer(act_map)
```

