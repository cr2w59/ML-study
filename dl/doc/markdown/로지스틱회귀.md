# 로지스틱 회귀

- Logistic Regression
- T/F를 판단하는 과정
  - 주어진 입력 값의 특징을 추출해 저장해 만든 model을 이용해 추후 비슷한 입력값에 대한 T/F를 판단

### 1. 정의

: 선형 회귀와 마찬가지로 적절한 선을 그리는 과정이지만 직선이 아니라 참(1)과 거짓(0) 사이를 구분하는 S자 형태의 선을 긋는 작업

| 공부한 시간 |   2    |   4    |   6    |  8   |  10  |  12  |  14  |
| :---------: | :----: | :----: | :----: | :--: | :--: | :--: | :--: |
|  합격 여부  | 불합격 | 불합격 | 불합격 | 합격 | 합격 | 합격 | 합격 |

<img src="C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200215170058217.png" alt="image-20200215170058217" style="zoom: 50%;" />



### 2. 시그모이드 함수

- Sigmoid Function

$$
y = \frac{1}{1+e^{(-ax+b)}}
$$

-  *e*: 자연 상수(2.71828...)

-  ***a*: 그래프의 경사도 (a와 경사도는 비례)**

    ​	<img src="C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200215172412101.png" alt="image-20200215172412101" style="zoom: 67%;" />

    - **a가 작아질수록 오차는 무한대로 커지지만, a가 커진다고 해서 오차가 없어지지는 않음**

      <img src="C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200215173313016.png" alt="image-20200215173313016" style="zoom: 67%;" />

-  ***b*: 그래프의 좌우 이동**

    ​	<img src="C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200215172536094.png" alt="image-20200215172536094" style="zoom: 67%;" />

    - **b가 너무 크거나 작을 경우 오차는 이차 함수 그래프와 유사한 형태로 나타남**

      ![image-20200215173348988](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200215173348988.png)

### 3. 오차 공식

- 시그모이드 함수의 특징은 y값이 0과 1 사이라는 것
- 실제 값이 1일 때 예측 값이 0에 가까워지는 경우와 실제 값이 0일 때 예측 값이 1에 가까워지는 경우에 오차가 커짐 => 공식화한 것이 로그 함수

### 4. 로그 함수

<img src="C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200215174101895.png" alt="image-20200215174101895" style="zoom:50%;" />

- 파란선: 실제 값이 1일 때 `-log h`
- 빨간선: 실제 값이 0일 때 `-log(1-h)`

$$
loss = -\{y\log h+(1-y)\log(1-h)\}
$$

------

1. 리스트 x1_data, x2_data와 리스트 y_data를 만들어 데이터 저장, 학습률 설정

   ```python
   # x, y의 데이터 값
   data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]]
   x_data = [row[0] for row in data]
   y_data = [row[1] for row in data]
   
   learning_rate = 0.5
   ```

2. 기울기 a와 y절편 b의 값을 임의의 정함

   ```python
   a = tf.Variable(tf.random_uniform([1], dtype=tf.float64, seed=0))
   b = tf.Variable(tf.random_uniform([1], dtype=tf.float64, seed=0))
   ```
   
3. y에 대한 이차 방정식 `a₁x₁ + a₂x₂ + b`의 식을 세움

   ```python
   # y 시그모이드 함수의 방정식을 세움
   y = 1 / (1 + np.e**(-a * x_data + b))
   ```

4. 텐서플로 함수들로 RMSE를 구현

   ```python
   # loss를 구하는 함수
   loss = tf.reduce_mean(np.array(y_data) * tf.log(y) + (1 - np.array(y_data) * ))
   ```

5. 경사 하강법을 실행하는 단계

   ```python
   gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)
   ```

6. 결과 값 출력

   ```python
   with tf.Session() as sess:
     sess.run(tf.global_variables_initializer())
     for step in range(2001):
       sess.run(gradient_descent)
       if step % 100 == 0:
         print('Epoch: %.f, RMSE=%.04f, 기울기 a1=%.4f, 기울기 a2=%.4f, y절편 b=%.4f' %(step, sess.run(rmse), sess.run(a1), sess.run(a2), sess.run(b))) 
   ```

- gradient_descent.py

```python
# x1, x2, y의 데이터 값
data = [[2, 0, 81], [4, 4, 93], [6, 2, 91], [8, 3, 97]]
x1_data = [row[0] for row in data]
x2_data = [row[1] for row in data]
y_data = [row[2] for row in data]

# 학습률 값
learning_rate = 0.1

# 기울기 a와 y절편 b의 값을 임의로 정함
# 단, 기울기의 범위는 0~10 사이이며, y절편은 0~100 사이에서 변하게 함
a1 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))
a2 = tf.Variable(tf.random_uniform([1], 0, 10, dtype=tf.float64, seed=0))
b = tf.Variable(tf.random_uniform([1], 0, 100, dtype=tf.float64, seed=0))

# y에 대한 이차 방정식 a1x1 + a2x2 + b의 식을 세움
y = a1 * x1_data + a2 * x2_data + b

# 텐서플로 RMSE 함수
rmse = tf.sqrt(tf.reduce_mean(tf.square(y - y_data)))

# RMSE 값을 최소로 하는 값 찾기
gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)

# 텐서플로를 이용한 학습
with tf.Session() as sess:
  # 변수 초기화
  sess.run(tf.global_variables_initializer())
  # 2001번 실행(0번째를 포함하므로)
  for step in range(2001):
    sess.run(gradient_descent)
    # 100번마다 결과 출력
    if step % 100 == 0:
      print('Epoch: %.f, RMSE=%.04f, 기울기 a1=%.4f, 기울기 a2=%.4f, y절편 b=%.4f' %(step, sess.run(rmse), sess.run(a1), sess.run(a2), sess.run(b))) 
```

![image-20200215161754724](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20200215161754724.png)

#### 다중 선형 회귀를 그래프로 표현