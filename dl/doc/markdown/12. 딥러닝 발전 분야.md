# 딥러닝 발전 분야

1. 이미지 분류
   - 딥러닝으로 가장 빨리 사용되어서 성과를 낸 분야 
   - 이미지 인식 대회, ResNet은 150layer까지 설계한 바 있음
   - 사람의 인지 능력을 추월, 한계도 존재하기 때문에 대회 더이상 없으며 아직도 어려운 분야
   - 트렌드가 이미지 분류에서 이미지 생성으로 옮겨감
   - CNN을 기반으로 작업 => 생성을 위해 GAN(적대적 신경망) 많이 사용
2. 음성 인식
   - 딥러닝을 적용해 상용화까지 성공한 분야
   - 과거: GMM(음소인식) + HMM(시퀀셜정보알고리즘) + AM(HMM을 통과한 데이터를 학습해 만든 음향모델) + LM(n-gram 기반 언어모델) + WFST(최종결합) 으로 구현 => ASR(자동 음성 인식)
   - 현재: DNN(딥러닝대체) -> 음향모델은 시계열 데이터를 처리하는 LSTM으로 대체 + end-to-end 방식 적용
3. 기계 번역
   - 자연어 처리의 최종 단계
   - 딥러닝으로 인해 정복되었음
   - history
     - 1950: RBMT(규칙기반 기계번역)
     - 1960: SMT(통계기반 기계번역)
4. 생성 모델 학습(최근 2~3년 가장 유행)
   - 이미지 분류, 텍스트 분류, 판독 => 판별 모델 학습
   - 현재는 생성모델 학습에 집중
   - 데이터 X에 대한 Y를 찾는 게 아닌 X의 분포에 집중해서 X 자체를 묘사하는 방향으로 진행 -> 적대적학습(GAN), 변분오토인코더(VAE) 등이 발전 중

![](https://github.com/cr2w59/pengsoo/blob/master/dl/doc/images/자연어처리의전통적인방법과딥러닝처리방법비교.png?raw=true)



# 자연어 처리

## 과거
- 복잡함, 무거움, 구현 어려움
- 오차 전파 현상: 각 단계에서 발생되는 오차가 중첩, 가중 되어서 뒤로 전파되는 현상

## 딥러닝
- 자연어 처리의 최신 주류 기법으로 사용
- 단어의 임베딩(벡터화)을 통해서 연속적인 벡터로 표현이 가능 -> 단어를 수치로 표현 가능
- 모호성, 유의성 해결 가능
- end-to-end 모델을 사용함-> 성능 향상
- 딥러닝 도입 이후 RNN이 주류였으나 단점을 보완한 LSTM, GRU 등 활용이 고도화 되었음 -> 어텐션의 등장 긴 길이의 시퀀스 처리도 쉽게 훈련이 가능

![](https://github.com/cr2w59/pengsoo/blob/master/dl/doc/images/심볼릭데이터와연속데이터의특징.png?raw=true)

![](https://github.com/cr2w59/pengsoo/blob/master/dl/doc/images/딥러닝기반으로자연어를처리하는과정.png?raw=true)



### 프로세스

1. **코퍼스(말뭉치) 확보**
2. **전처리(품질향상)**
3. **단어의 임베딩(수치화/벡터화)**
4. **신경망 구축( RNN or LSTM or GRU )->학습->평가**
5. **디코딩: 결과값을 획득**

