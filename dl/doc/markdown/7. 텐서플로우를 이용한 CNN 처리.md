# 1. 연구목표

- MNIST 손글씨 이미지 데이터를 사용
- 손글씨 이미지를 분류
- 알고리즘 목적
  - 딥러닝의 CNN을 이용해서 손글씨를 예측하는 모델 구축
  - 예측 모델 도출, 정확도 평가 후 관찰
- 딥러닝 엔진 중 텐서플로우를 이용해 구현

# 2. 데이터 확보/수집

```python
import tensorflow as tf
%tensorflow_version 1.x
mnist = tf.keras.datasets.mnist.load_data(path='mnist.npz')

type(mnist), len(mnist[0][0]), mnist[0][1], len(mnist[1][0]), mnist[1][1]
# 훈련용 데이터: mnist[0][0]
# 훈련용 레이블: mnist[0][1]
# 테스트용 데이터: mnist[1][0]
# 테스트용 레이블: mnist[1][1]
# 레이블은 벡터화가 안 되어 있고, 분류형으로 0~9까지 배치
```

* 레이블이 이미 벡터화 되어서 제공되는 tf의 데이터셋 활용(1.x에서만 사용 가능)

```python
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('./data/mnist/', one_hot=True)

# 이미지 데이터는 28x28 픽셀로 처리되었고 레이블은 0~9를 0과 1로 구성하는 벡터화 처리 되었음
mnist.train.images.shape, mnist.train.labels.shape
mnist.train.labels[:3]
# 이미지 데이터는 float
mnist.train.images
```

# 3. 데이터 준비

```python
# 벡터화된 레이블을 보고 원래값 0~9를 찾아내는 방법 확인
# 힌트 => 배열 10칸 중에서 1이 존재하는 인덱스 값 => 실제 수치값
type(mnist.train.labels)
import numpy as np
np.where( mnist.train.labels[:1][0] )[0][0]

pixels = mnist.train.images.shape[1] # 이미지 1개당 피쳐의 크기
nums = mnist.train.labels.shape[1]   # 레이블 1개당 피쳐의 크기
pixel_wh_size = int(np.sqrt(pixels)) # 이미지 가로 크기 혹은 세로 크기
```

# 4. 데이터 분석(생략)

# 5. 모델링

## 5-1. 데이터 플로우 그래프 구축
- 레이어를 구축하면서 상수, 변수, 플레이스홀더, 연산 등의 요소를 정의
- 레이어 구축 및 연결(원칙: 앞단계의 출력은 뒷단계의 입력이 됨)
  - 입력층
  - 합성곱층a
  - 풀링층a
  - 합성곱층b
  - 풀링층b
  - 전결합층
  - 드롭아웃층
  - 출력층

### 입력층

```python
# x: 외부에서 손글씨 이미지 데이터가 들어오는 플레이스홀더
# shape(n, 784): 이미지 1개를 표현하는 데 feature 784개 필요
x = tf.placeholder(tf.float32, shape=(None,pixels), name='x')
```

### 합성곱층a

#### *W*
- 가중치를 파라미터로 가지는 필터값 필요
- 행렬, 외부에서 주입(X), 내부적인 함수를 활용해 생성 => 텐서의 타입 중 Varibale
- 2개의 합성곱층에서 W가 각각 필요 => W를 만드는 함수 필요

```python
# 가중치-------------------------------------------------------------------------------
# shape: 가중치를 공용 파라미터로 가지는 필터(=커널)의 shape / 커널의 크기가 무조건 3x3은 아님
# name:  각 구성원들의 이름을 구분하기 위해서 직접 부여
def makeWeightVariable(shape, name):
  # 변수의 초기값 -> 절단 정규분포를 통한 난수를 발생하는 함수 활용
  # shape 크기에 맞춰서 배열을 만들고, 함수가 계산해서 난수를 배치함(커널 크기만큼 행렬이 만들어지고, 난수가 설정됨) 
  W_initValue = tf.truncated_normal(shape, stddev=0.1)
  W = tf.Variable(W_initValue, name=f'W_{name}')
  return W

# bias--------------------------------------------------------------------------------
# 변수로 정의하고 고정 임계값으로 0.1을 임시 부여
def makeBiasVariable(shape, name):
  b_initValue = tf.constant(0.1, shape=[shape])
  b = tf.Variable(b_initValue, name=f'b_{name}')
  return b

# 합성곱 계층--------------------------------------------------------------------------
def makeConv2d(x, W):
  conv2d = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')
  return conv2d

'''
tf.nn.conv2d(
    input: x => [batch: 1회에 훈련하고자 하는 이미지의 총 개수, 
                in_height: 세로 크기, in_width: 가로 크기, 
                in_channels: color에 따라 다름]
    filters:(=kernel, 필터의 공용 파라미터, 필터를 구성하는 구성원의 값 W)
            => [filter_height, filter_width: 필터의 크기, 
                in_channels: 입력채널수 -> 1, 
                out_channels: 출력채널수 -> 임의의 값]
    strides: {int scalar}, {int list} lenght=1 or 2 or 4
            => [batch, w, h, depth] batch, depth는 통상적으로 1 사용 / w, h는 일반적으로 같은 값
            => [1, 1, 1, 1]
    padding: 특성맵 보정, 외곽에서 개수가 부족할수도 있는데 이를 통상 0으로 테두리 보정(SAME)
    data_format='NHWC',
    dilations=None,
    name=None
)
'''
```

```python
# 합성곱층a 생성: 텐서보드 상에 작업 공간을 잡음
with tf.name_scope('conv1') as scope:
  # W / shape=[filter_height, filter_width, in_channels, out_channels]
  W_conv1 = makeWeightVariable([5, 5, 1, 32], name='conv1')
  # b / b의 shape = W의 out_channels
  b_conv1 = makeBiasVariable(32, name='conv1')
  # x => [batch, h, w, channels]
  x_image = tf.reshape(x, [-1, pixel_wh_size, pixel_wh_size, 1])

  # 컨볼루션 레이어 생성
  # 활성화 함수를 통과시켜서 레이어의 출력물(특성맵)을 비선형으로 보정(활성화맵)
  h_conv1 = tf.nn.relu(makeConv2d(x_image, W_conv1))

# h_conv1의 크기는 stride, padding에 의해 원본과 달라질수도 있음
h_conv1.shape
```

### 풀링층a

- 특성맵(or 활성화맵)의 특성을 강화
- 최대풀링, 평균풀링, 최소풀링 등 여러개 값 중 하나를 취해서 행렬을 새로 구성(축소)
- 샘플링한다고 표현
- 크기에 관여 => 얼마만큼 이동하면서 처리할 것인가(stride)
- 커널에 파라미터는 없지만 최대/평균/최소 등의 의미는 가짐
- input: 합성곱층a의 결과(h_conv1)  

```python
# x: 외부에서 손글씨 이미지 데이터가 들어오는 플레이스홀더
# shape(n, 784): 이미지 1개를 표현하는 데 feature 784개 필요
x = tf.placeholder(tf.float32, shape=(None,pixels), name='x')
```

### 합성곱층b

```python
# x: 외부에서 손글씨 이미지 데이터가 들어오는 플레이스홀더
# shape(n, 784): 이미지 1개를 표현하는 데 feature 784개 필요
x = tf.placeholder(tf.float32, shape=(None,pixels), name='x')
```

### 풀링층b

```python
# x: 외부에서 손글씨 이미지 데이터가 들어오는 플레이스홀더
# shape(n, 784): 이미지 1개를 표현하는 데 feature 784개 필요
x = tf.placeholder(tf.float32, shape=(None,pixels), name='x')
```

### 전결합층

```python
# x: 외부에서 손글씨 이미지 데이터가 들어오는 플레이스홀더
# shape(n, 784): 이미지 1개를 표현하는 데 feature 784개 필요
x = tf.placeholder(tf.float32, shape=(None,pixels), name='x')
```

### 드롭아웃층

```python
# x: 외부에서 손글씨 이미지 데이터가 들어오는 플레이스홀더
# shape(n, 784): 이미지 1개를 표현하는 데 feature 784개 필요
x = tf.placeholder(tf.float32, shape=(None,pixels), name='x')
```

### 출력층

```python
# x: 외부에서 손글씨 이미지 데이터가 들어오는 플레이스홀더
# shape(n, 784): 이미지 1개를 표현하는 데 feature 784개 필요
x = tf.placeholder(tf.float32, shape=(None,pixels), name='x')
```



## 5-2. 실행(학습, 예측, 평가)
- 데이터를 준비(batch) -> 학습 -> 예측 -> 평가(출력)

