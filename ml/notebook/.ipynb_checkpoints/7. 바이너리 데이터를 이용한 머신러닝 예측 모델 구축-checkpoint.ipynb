{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손글씨 이미지 데이터 MNIST\n",
    "\n",
    "- 인코딩된 바이너리 데이터를 디코딩하여 처리하는 방식 확인\n",
    "- 지도 학습\n",
    "- 학습용 데이터는 6만개, 테스트 데이터는 1만개\n",
    "- 결론\n",
    "    - 학습 후 새로운 데이터 입력시 판별\n",
    "    - 0~9까지의 손글씨 이미지를 판별\n",
    "    - 데이터는 url을 직접 획득해서, 원하는 곳에 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  No  | 단계                         | 내용                                                         |\n",
    "| :--: | :--------------------------- | :----------------------------------------------------------- |\n",
    "|  1   | 연구목표                     | - 손글씨 이미지(0~9)를 학습시켜서 새로운 손글씨 이미지를 판별하는 머신러닝 모델 구축<br>- 이미지 압축 해제<br>- 데이터 디코딩<br>- 28x28로 구성된 픽셀 이미지 벡터화<br/>- 시스템 통합의 결과를 보고 연구 목표 설정 필요하지만 시스템 통합 생략 |\n",
    "|  2   | 데이터획득/수집              | - http://yann.lecun.com/exdb/mnist/ 접속<br>- Web Scraping을 통해 데이터의 URL 획득<br/>- 지정된 위치에 다운로드 -> 압축해제 |\n",
    "|  3   | 데이터준비/전처리            | - 디코딩(내부구조를 알 수 있는 인코딩 문서(MNIST Database) 필요)<br>- 에디언 처리<br>- 벡터화 |\n",
    "|  4   | 데이터탐색/통찰/시각화분석   | - skip                                                       |\n",
    "|  5   | 데이터모델링(머신러닝모델링) | - 분류 알고리즘 사용<br>- 알고리즘 선정- > 학습/테스트데이터 -> 학습 -> 예측 -> 성능평가 |\n",
    "|  6   | 시스템통합                   | - skip                                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터 획득/수집\n",
    "- 모듈 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootUrl = 'http://yann.lecun.com/exdb/mnist/'\n",
    "soup = BeautifulSoup(req.urlopen(rootUrl), 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train-images-idx3-ubyte.gz, ... 등 총 4개 url 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train-images-idx3-ubyte.gz',\n",
       " 'train-labels-idx1-ubyte.gz',\n",
       " 't10k-images-idx3-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [ tt.a.string for tt in soup.findAll('tt')[:4]]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다운로드 > 압축해제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path, gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 다운로드 위치 선정\n",
    "savePath = '../data/mnist'\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da10480fd4414c18994422928d24d13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "대상 ../data/mnist/train-images-idx3-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "대상 ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "대상 ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "대상 ../data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 진행률 모듈\n",
    "from tqdm import tqdm_notebook\n",
    "for file in tqdm_notebook(files):\n",
    "    print('소스', rootUrl+file)\n",
    "    \n",
    "    # 저장 위치 및 파일명\n",
    "    local_path = f'{savePath}/{file}'\n",
    "    print('대상', local_path)\n",
    "    \n",
    "    # 웹상에 존재하는 리소스를 로컬 디스크에 직접 저장\n",
    "    req.urlretrieve(rootUrl+file, local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67ccd131d9448f2a71195af52bb00bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 압축해제\n",
    "for file in tqdm_notebook(files):\n",
    "    # 원본 파일의 경로\n",
    "    ori_gzip_file = f'{savePath}/{file}'\n",
    "    # 압축해제 파일의 경로\n",
    "    target_file = f'{savePath}/{file[:-3]}'\n",
    "    # 압축해제\n",
    "    with gzip.open(ori_gzip_file, 'rb') as fg:\n",
    "        tmp = fg.read()\n",
    "        with open(target_file, 'wb') as f:\n",
    "            f.write(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 준비/전처리 \n",
    "\n",
    "- 디코딩(내부구조를 알 수 있는 인코딩 문서(MNIST Database) 필요)\n",
    "- 에디언(Endian) 처리(TCP/IP 상에서 통신 수행시 중요)\n",
    "    - 컴퓨터 메모리와 같은 1차원 공간에 여러 개의 연속된 데이터를 배열하는 방법\n",
    "    - 종류: 바이트를 배치하는 순서에 따라\n",
    "        - 빅 에디언: 값을 앞에서부터 채움(ex. 0x12 0x34 0x56 0x78)\n",
    "        - 리틀 에디언: 값을 뒤에서부터 채움(ex. 0x78 0x56 0x34 0x12)\n",
    "- 벡터화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LABEL FILE\n",
    "    - magic number: 4byte -> 에디안 체크\n",
    "    - LABEL 수: 4byte -> 에디안 체크\n",
    "    - LABEL 데이터: 1byte -> 0~9\n",
    "    - 크기: 4 + 4 + LABEL 수 * 1byte = 8 + 60000 = 60008byte\n",
    "- IMAGE FILE\n",
    "    - magic number: 4byte -> 에디안 체크\n",
    "    - 손글씨 이미지 개수: 4byte -> 에디안 체크\n",
    "    - 가로크기(픽셀수) : 4byte -> 에디안 체크\n",
    "    - 세로크기(픽셀수) : 4byte -> 에디안 체크\n",
    "    - 픽셀값 : unsigned 1byte -> 0~2^8-1: 0~255(0xFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바이너리 데이터를 빅/리틀 에디안 방식으로 특정 바이트만큼 읽는 기능 제공\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2049 10000\n",
      "2051 10000 28 28\n",
      "이미지 파일의 크기: 7840016 bytes\n"
     ]
    }
   ],
   "source": [
    "# 헤더 정보 추출\n",
    "label_f = open('../data/mnist/t10k-labels-idx1-ubyte','rb')\n",
    "image_f = open('../data/mnist/t10k-images-idx3-ubyte','rb')\n",
    "# 바이너리 데이터는 헤더부터 읽어서 데이터의 유효성이나 종류를 인지함\n",
    "# MNIST 규격서: high edian(>)으로 기술돼있고, label은 헤더가 4+4=8byte이다\n",
    "label_magic_number, label_count = struct.unpack('>II',label_f.read(4+4))\n",
    "image_magic_number, image_count, row, col = struct.unpack('>IIII',image_f.read(4+4+4+4))\n",
    "\n",
    "print(label_magic_number, label_count)\n",
    "print(image_magic_number, image_count, row, col)\n",
    "print('이미지 파일의 크기:', 4+4+4+4+image_count*row*col,'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_f = open('../data/mnist/t10k.csv', 'w', encoding='utf-8')\n",
    "pixels = row * col\n",
    "\n",
    "for idx in range(image_count):\n",
    "    # 정답 추출\n",
    "    label_tmp = struct.unpack('B', label_f.read(1))\n",
    "    label = label_tmp[0]\n",
    "    \n",
    "    # 이미지 추출\n",
    "    binaryData = image_f.read(pixels)\n",
    "    strData = list(map(lambda x : str(x), binaryData))\n",
    "    csv_f.write(str(label)+',')\n",
    "    csv_f.write(','.join(strData)+'\\n')\n",
    "    \n",
    "    # pgm 파일로 dump(데이터 유효성 확인 위함)\n",
    "    with open(f'../data/mnist/{label}.pgm','w',encoding='utf-8') as f:\n",
    "        f.write('P2 28 28 255\\n' + ' '.join(strData))\n",
    "    # 이미지 데이터의 벡터화\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_f.close()\n",
    "image_f.close()\n",
    "csv_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12117c777bce47f4922dd7c8c9df2bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a68d56d49949438c248544f6d1ee49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decoding_mnist_rawData(dataStyle='train', maxCount=0):\n",
    "    label_f = open(f'../data/mnist/{dataStyle}-labels-idx1-ubyte','rb')\n",
    "    image_f = open(f'../data/mnist/{dataStyle}-images-idx3-ubyte','rb')\n",
    "    csv_f = open(f'../data/mnist/{dataStyle}.csv', 'w', encoding='utf-8')\n",
    "    label_magic_number, label_count = struct.unpack('>II',label_f.read(4+4))\n",
    "    image_magic_number, image_count, row, col = struct.unpack('>IIII',image_f.read(4+4+4+4))\n",
    "\n",
    "    pixels = row * col\n",
    "\n",
    "    for idx in tqdm_notebook(range(image_count)):\n",
    "        if idx >= maxCount: break\n",
    "        label_tmp = struct.unpack('B', label_f.read(1))\n",
    "        label = label_tmp[0]\n",
    "\n",
    "        binaryData = image_f.read(pixels)\n",
    "        strData = list(map(lambda x : str(x), binaryData))\n",
    "        csv_f.write(str(label)+',')\n",
    "        csv_f.write(','.join(strData)+'\\n')\n",
    "\n",
    "        with open(f'../data/mnist/{label}.pgm','w',encoding='utf-8') as f:\n",
    "            f.write('P2 28 28 255\\n' + ' '.join(strData))\n",
    "        \n",
    "    label_f.close()\n",
    "    image_f.close()\n",
    "    csv_f.close()\n",
    "decoding_mnist_rawData('t10k',2500)\n",
    "decoding_mnist_rawData('train',7500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [M1] 데이터 품질 향상\n",
    "\n",
    "- 정확도가 떨어지면 데이터의 품질과 양을 확인\n",
    "    - 데이터 개수 조정\n",
    "    - 데이터 품질 조정\n",
    "        - 정규화\n",
    "        - feature 수를 줄이는 PCA(비지도 학습의 차원축소)\n",
    "    - 훈련과 테스트의 비율 조정\n",
    "    \n",
    "- 96%의 정확도를 목표로!\n",
    "\n",
    "**모델개선조치**\n",
    "1. 알고리즘 교체\n",
    "2. 하이퍼파라미터 튜닝\n",
    "3. 파이프라인을 이용한 전처리기 활용\n",
    "4. 교차 검증법을 활용\n",
    "5. ROC곡선, AUC값 등으로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(dataType='train'):\n",
    "    f = open(f'../data/mnist/{dataType}.csv', 'r')\n",
    "    \n",
    "    labels = list()\n",
    "    images = list()\n",
    "    \n",
    "    while True:\n",
    "        row = f.readline()\n",
    "        if not row: break\n",
    "        labels.append(int(row.split(',')[0]))\n",
    "        images.append(list(map(lambda x: int(x), row.split(',')[1:])))\n",
    "    f.close()\n",
    "    return { 'labels':labels, 'images':images }\n",
    "train = load_csv('train')\n",
    "test = load_csv('t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 데이터모델링(머신러닝모델링)\n",
    "- 지도학습 데이터이므로 정확도를 통해서 평가를 1차로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# 1. 모듈 준비\n",
    "from sklearn import svm, model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 알고리즘 생성\n",
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 7500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 데이터 분류(이미 완료함)\n",
    "len(train['images']), len(train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 학습\n",
    "clf.fit(train['images'], train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 예측\n",
    "predict = clf.predict(test['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 9, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 평가\n",
    "metrics.accuracy_score(test['labels'], predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       219\n",
      "           1       0.96      0.99      0.97       287\n",
      "           2       0.93      0.93      0.93       276\n",
      "           3       0.92      0.93      0.93       254\n",
      "           4       0.93      0.95      0.94       275\n",
      "           5       0.94      0.93      0.93       221\n",
      "           6       0.94      0.94      0.94       225\n",
      "           7       0.93      0.90      0.91       257\n",
      "           8       0.94      0.90      0.92       242\n",
      "           9       0.91      0.91      0.91       244\n",
      "\n",
      "    accuracy                           0.93      2500\n",
      "   macro avg       0.93      0.93      0.93      2500\n",
      "weighted avg       0.93      0.93      0.93      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. 오차행렬(혼동행렬)을 이용한 평가\n",
    "clf_report = metrics.classification_report(test['labels'], predict)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit( train['images'])\n",
    "X_train_scaled = scaler.transform( train['images'] )\n",
    "clf2 = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit( X_train_scaled, train['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score( scaler.transform(test['images']), test['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee758cfea2b4609b75e568c87333825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f35ffb30c844698ac0fcec88074c1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import struct\n",
    "from tqdm import tqdm_notebook\n",
    "def decoding_mnist_rawData(dataStyle='train', maxCount=0):\n",
    "    label_f = open(f'../data/mnist/{dataStyle}-labels-idx1-ubyte','rb')\n",
    "    image_f = open(f'../data/mnist/{dataStyle}-images-idx3-ubyte','rb')\n",
    "    csv_f = open(f'../data/mnist/{dataStyle}2.csv', 'w', encoding='utf-8')\n",
    "    label_magic_number, label_count = struct.unpack('>II',label_f.read(4+4))\n",
    "    image_magic_number, image_count, row, col = struct.unpack('>IIII',image_f.read(4+4+4+4))\n",
    "\n",
    "    pixels = row * col\n",
    "\n",
    "    for idx in tqdm_notebook(range(image_count)):\n",
    "        if idx >= maxCount: break\n",
    "        label_tmp = struct.unpack('B', label_f.read(1))\n",
    "        label = label_tmp[0]\n",
    "\n",
    "        binaryData = image_f.read(pixels)\n",
    "        strData = list(map(lambda x : str(x), binaryData))\n",
    "        csv_f.write(str(label)+',')\n",
    "        csv_f.write(','.join(strData)+'\\n')\n",
    "\n",
    "        with open(f'../data/mnist/{label}.pgm','w',encoding='utf-8') as f:\n",
    "            f.write('P2 28 28 255\\n' + ' '.join(strData))\n",
    "        \n",
    "    label_f.close()\n",
    "    image_f.close()\n",
    "    csv_f.close()\n",
    "decoding_mnist_rawData('t10k',10000)\n",
    "decoding_mnist_rawData('train',30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(dataType='train'):\n",
    "    f = open(f'../data/mnist/{dataType}2.csv', 'r')\n",
    "    \n",
    "    labels = list()\n",
    "    images = list()\n",
    "    \n",
    "    while True:\n",
    "        row = f.readline()\n",
    "        if not row: break\n",
    "        labels.append(int(row.split(',')[0]))\n",
    "        images.append(list(map(lambda x: int(x), row.split(',')[1:])))\n",
    "    f.close()\n",
    "    return { 'labels':labels, 'images':images }\n",
    "train2 = load_csv('train')\n",
    "test2 = load_csv('t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = svm.SVC()\n",
    "\n",
    "# 4. 학습\n",
    "clf3.fit(train2['images'], train2['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 예측\n",
    "predict3 = clf3.predict(test2['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 평가\n",
    "metrics.accuracy_score(test2['labels'], predict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.98      0.97      1032\n",
      "           3       0.97      0.98      0.97      1010\n",
      "           4       0.97      0.98      0.97       982\n",
      "           5       0.98      0.97      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.96      0.96      1028\n",
      "           8       0.97      0.97      0.97       974\n",
      "           9       0.97      0.95      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. 오차행렬(혼동행렬)을 이용한 평가\n",
    "clf_report3 = metrics.classification_report(test2['labels'], predict3)\n",
    "print(clf_report3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
