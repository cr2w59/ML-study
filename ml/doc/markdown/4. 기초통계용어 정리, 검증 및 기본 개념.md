## 통계 모델링 vs 머신러닝 모델링

| 순서 | 통계                                                         | 머신러닝                                                     |
| :--: | :----------------------------------------------------------- | :----------------------------------------------------------- |
|  1   | 변수간 관계를 수학식으로 정형화                              | 데이터로부터 학습이 가능한 알고리즘을 사용<br>(규칙 기반 프로그래밍 방식이 필요 없음) |
|  2   | 전제, 데이터에 맞는 모델 적합화 수행 전 곡선 형태를 가정<br>(선형, 다형) | 주어진 데이터로부터 복잡합 패턴을 스스로 학습<br>(곡선 형태의 가정 필요 없음) |
|  3   | 표현 ex. 85%의 정확도, 92%의 신뢰수준으로 결과 예측          | 표현 ex. 정확도 86%로 예측(분류), <br>성능평가지수 0.5로 수렴(회귀) |
|  4   | P값의 다양한 매개변수 결과를 예측                            | 통계적 유의성 전달 안 함                                     |
|  5   | 훈련:테스트=7:3                                              | 훈련:테스트=(50:25):25                                       |
|  6   | 훈련 데이터만으로 개발                                       | 훈련/검증 데이터 필요                                        |
|  7   | 연구 목적, 증명 대부분                                       | 실제 환경을 구현                                             |
|  8   | 통계학과, 수학과                                             | 전산학과                                                     |



## 통계 기본 이론

- 예측 분석학
- 대전제: 역사는 반복적이다
- 과거 데이터에 대한 적합화를 수행하여 이를 테스트함
  - 결과 성능에 대한 척도가 검증되면, 동일모델에서 미래 예측에 활용
- 독립 변수(=관측치, 입력변수, 특징, feature, 설명변수)
- 종속 변수(=레이블, 결과변수, 반응변수, 응답변수, 설명된변수, 측정된변수, 실험변수)
- 변수들로 이루어진 수학식으로 계산 후 실제에 적용, 추정
- 모든 변수들이 만족하는 기본 가정 존재

## 기술 통계 용어 정리

![](C:\Users\admin\Documents\GitHub\pengsoo\ml\table\s_0.png)

* 모집단: 데이터 **전체**, 관측값 전체, 연구 중 데이터 전체
* 표본: 모집단의 부분 집합, 분석 중 모집단의 **일부**
* 매개변수

![](C:\Users\admin\Documents\GitHub\pengsoo\ml\table\s_1.png)

* 평균: 산술평균 / 이상치(특이값)의 영향이 큼
* 중간값: 정렬한 데이터의 가운데 값

```python
# scipy를 이용하여 통계 처리
from scipy import stats
import numpy as np
import pandas as pd
data = [5,2,6,8,7,4,5,1,9,5,8,3,6,6,2,1,4,5,8,4,7,6,2,3,2,1,4,7,8,8,4,5,6,9,5,6,8,2,3,6,1,4,7]
# scipy의 베이스는 numpy. numpy는 array가 기본 자료형
data = np.array( data )

# 평균
np.mean(data), round(np.mean(data),2)
# 중간값
np.median(data)
# 최빈값
mode = stats.mode(data)
mode, mode[0][0]
df = pd.DataFrame(data)
df.describe()
```



### 산포도

* 산포

  * 데이터가 얼마나 퍼져 있는가(변량)
  * 데이터 변수가 부적합한 값을 가지고 있는지 측정
  * 데이터가 중심에 모이지 않고 얼마나 흩어져있는지 제공

* 범위

  * 최대값과 최소값의 차이

* 분산

  * 평균과 관측값의 차이를 제곱한 값들의 평균
  * 기대값으로부터 얼마나 떨어진 곳에 데이터가 분포하는지 가늠하는 수치

* 표준편차

  * 분산의 제곱근
  * 분산보다 더 많이 활용됨

* 분위수

  * 데이터를 동일한 조각으로 분할

  ![](C:\Users\admin\Documents\GitHub\pengsoo\ml\table\s_2.png)

  

### 정규분포

![](C:\Users\admin\Documents\GitHub\pengsoo\ml\table\확률변수_확률분포_확률_이산확률변수.jpg)

- 동전을 두번 던진다. 동전은 앞면(H), 뒷면(T) 2개가 존재한다

  - 동전을 두번 던졌을때 나올 수 있는 경우의 수(S). S={HH, HT, TH, TT}
    - **정의역, 표본공간, S**
  - 동전을 두번 던졌을때 앞면이 나오는 케이스는
    - HH ->2, HT, TH ->1 TT ->0 에 대응
    - 0, 1, 2 이것을 실수 공간 값들 중에서 HH가 0에 대응하고, HT와 TH가 1에 대응하도록 정의하는 게 대응방식 -> 관계를 정의하는 함수 -> 확률변수

- 정의역이 표본공간이고, 공역이 실수 전체의 집합인 함수가 *확률변수*

- 실수 공간(공역)의 어떤 값이 표본 공간(S)의 원소들과 어떻게 연결할지 정의하는 함수가 *확률변수*

  

- **이산확률변수**: 공역을 셀 수 있을때의 확률변수

- **확률분포**: 공역인 X를 정의역으로, 확률을 공역으로 봤을 때 두 가지가 대응되는 관계->함수->확률분포

- **정규분포**

  - 가우시안 분포

  - 연속 확률 분포의 하나

  - 수집된 자료(표본)의 분포를 근사하는 데 사용

    ![](https://dbscthumb-phinf.pstatic.net/3955_000_1/20180117204936312_0S0V0BBAE.gif/EchelonApprox.gif?type=w646_fst_n)

  - 특징

    - 중심극한정리: 독립적인 확률변수들의 평균이 정규분포에 가까워지려는 성질

      - ex. 입학 시험 점수가 정규 분포를 따른다.

        - 평균 점수가 52점이다. 표준편차 16.3인 경우

        - 몇 %가 67점이상을 받을 것인가?

          ![](C:\Users\admin\Documents\GitHub\pengsoo\ml\table\s_4.png)

    ```python
    xbar = 67
    mu = 52
    s = 16.3
    
    # z-score 표준값
    # 정규분포를 만들고, 개개의 경우가 표준편차상의 어떤 위치를 차지하는지 보여주는 수치
    z = (xbar-mu) / s
    
    # 67점 이상 면적이 어떻게 되는가 -> 곡선하 확률 면적 계산
    p = 1 - stats.norm.cdf(z)
    round(p*100, 2)
    ```

    

### 카이제곱검정

- 범주형 데이터의 통계 분석시 사용
- 2개의 범주형 변수 X, Y가 있다
- 2개의 변수 사이의 통계적인 상관성이 존재하는가

```python
import pandas as pd
from scipy import stats
survey = pd.read_csv('../table/survey.csv')
survey.Smoke.unique()
survey.Exer.unique()
# 목적: Smoke항목과 Exer항목간 상관성을 검정
# 빈도: 특정 변수에 대한 값의 빈도를 재구성
tmp = pd.crosstab( survey.Smoke, survey.Exer, margins=True )
src_df=tmp.iloc[:-1,:-1]
# p값 획득
p_value = stats.chi2_contingency( observed=src_df )
p_value=round(p_value[1],2)
# 판단
if p_value < 0.05:
    print('강한 상관 관계')
else:
    print('두 변수는 서로 독립적이다')
```



## 가설검정

- 표본으로 통계적 테스틀 수행할 때, 모집단에 대한 추론을 만드는 과정

1. 귀무가설
   - 처음부터 버릴 것으로 예상하고 만드는 가설
   - 통계학적으로 증거를 통해 증명하려는 가설
2. 대립가설
   - 검정을 직접 수행하기가 어려움
   - 귀무가설을 기각함으로써 받아들여지는 결론

- p값

  - 귀무가설이 옳다는 전제하에, 표본에서 실제 관측된 통계값과 같거나 더 극단적인 값이 관측될 확률
  - p값이 작을수록 귀무가설에 반하는 강력한 증거
  - p값은 귀무가설에 반하는 증거를 측정하는 수치(확률)

- 유의 수준

  - 판단의 기준이 되는 임계값(치)
  - 유의 수준을 a, 신뢰수준은 95%라고 할 때 
    - 1 - 0.95 => 0.05 = a가 유의 수준 값

- 예

  - 과자 공장 A사
  - 주장: 제품 B의 중량 1000g 이상이다
  - 증명
    1. 표본: 과자 30개 무작위로 추출, 무게를 측정, 평균 냄
    2. 측정치: 990g
    3. 표준편차: 분산(평균과 관측값의 차-> 제곱-> 평균)의 제곱근이 12.5g
    4. 유의 수준 5%: 0.05로 설정
    5. A사의 주장을 기각할 수 있는가?
  - 귀무가설: 제품 B의 중량은 1000g보다 크거나 같다
  - 대립가설: 제품 B의 중량은 1000g보다 작다

  ![](C:\Users\admin\Documents\GitHub\pengsoo\ml\table\s_3.png)

```python
from scipy import stats
xbar = 990 #표본의 평균
mu = 1000 #귀무가설에 의한 임계값
s = 12.5 #표준편차
n = 30 #표본수

t_sample = (xbar-mu) / (s / np.sqrt(float(n)))
p_value = stats.t.sf( np.abs(t_sample), n-1 )
# 유의수준(판단의 임계값) -> t-분포임계값 구할 수 있음
alpha = 0.05
# t-분포임계값
t_alpha = stats.t.ppf( alpha, n-1 )
if p_value < alpha:
    print('귀무가설을 기각-> 제품B는 1000g 미만')
else:
    print('귀무가설을 채택')
```



## 아노바 분산검정

- 둘 이상의 모집단의 평균이 서로 동일한지 테스트
- 귀무가설: 모든 모집단의 평균은 동일
- 대립가설: 최소 하나의 모집단의 평균은 다름
- 사례
  - 화학회사에서 모든 농작물에 적용 가능한 만능 비료 개발
  - 수확량이 비슷한지 여러 작물에 각각 적용한 데이터 획득

```python
import pandas as pd
from scipy import stats
df = pd.read_csv('../table/fetilizers.csv')
# 아노바 분산
anova = stats.f_oneway( df[df.columns[0]], df[df.columns[1]], df[df.columns[2]] )
p_value = round(anova[1],2)
if p_value < 0.05:
    print('귀무가설 채택')
else:
    print('귀무가설 기각', anova[1]-0.05, '만큼만 향상시키면 성립')
```

