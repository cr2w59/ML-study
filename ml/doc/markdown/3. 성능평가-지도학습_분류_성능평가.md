## 성능평가

- 평가 항목 방식 케이스
    - 지도학습의 분류
        - 혼동행렬(정확도, f1-score, 정밀도, 재현율), AUC, ROC
    - 지도학습의 회귀
        - 손실
    - 비지도학습
    - 강화학습

### 머신러닝 > 지도학습 > 분류 > 성능평가 지표

- 통계학의 혼동행렬이라는 항목을 이용하여 평가
- 개요
    - 예측값이 실제 관측값을 얼마나 정확하게 예측했는가?
    - 이 사항을 보여주는 행렬
    - 예
        - 암 여부를 예측했는데 실제로도 악성인지 예측하는 예
        - 실제는 병이 있었는데 있다고 예측/없다고 예측
        - 실제는 병이 없었는데 있다고 예측/없다고 예측

|   실제   | 예측 Positive | 예측 Negative |
| :------: | :-----------: | :-----------: |
| Positive |      TP       |      FN       |
| Negative |      FP       |      TN       |

- 참긍정: TP
    - 병이 있다고 예측, 실제로 병이 있음
- 참부정: TN
    - 병이 없다고 예측, 실제로 병이 없음
- 거짓긍정: FP(1종 오류)
    - 병이 있다고 예측, 실제로 병이 없음
- 거짓부정: FN(2종 오류)
    - 병이 없다고 예측, 실제로 병이 있음



- 정밀도(precision)
    - 병이 있다고 예측을 했는데, 실제로 병이 있는 비율. 정답율
    - P = TP / (TP + FP)
- 재현율(recall)
    - 실제로 병이 있는 전체 데이터 중에 참긍정 비율
    - R = TP / (TP + FN)
- F1 점수
    - 정밀도와 재현율의 조화평균(Harmonic mean)
    - F1 = 2 / (1/P + 1/R)
- 특이성
    - 실제 병이 없는 전체 중 참부정(TN)의 비율
    - TN / (TN + FP)
- 곡선하 면적(ROC): Area under Curve ROC => ROC 곡선
    - 참긍정률과 거짓부정률 사이의 관계 표현
    - 1 - 특이성
    - AUC: ROC의 상세값(수치)

```python
from matplotlib import pyplot as plt
from sklearn.datasets import load_iris
import pandas as pd
def attach_iris():
    ds = load_iris()
    df = pd.DataFrame(ds.data, columns=ds.feature_names)
    # species라는 컬럼 추가 => 값은 setosa, versicolor, virginica 중 하나로 설정
    df['species'] = ds.target_names[ds.target]
#     df['species'] = ds.target
    return df
```



### 분류 알고리즘을 다양하게 사용하여 교차 성능평가 수행

- 하이퍼파라미터 튜닝 + 파이프라인

- 각각 알고리즘별로 적용하여 시각화 및 수치 비교(사용)

  

```python
import sklearn
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
# 알고리즘
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
# 알고리즘 시각화를 위해 사전 설정
# 선형 그래프의 모양을 지정
# 파라미터 값은 임의로 부여
class_map = {
    'LogisticRegression':('-', LogisticRegression() ),
    'DecisionTreeClassifier':('--', DecisionTreeClassifier(max_depth=5) ),
    'RandomForestClassifier':('.-', RandomForestClassifier(max_depth=5, 
                                                           n_estimators=10, max_features=1) ),
    'GaussianNB':(':', GaussianNB() ),
    'SVC':('-*', SVC(probability=True) )
}
# 데이터 정리
X = df[df.columns[:4]]
Y = df['species'] == 'versicolor'
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.8)
# 시각화를 통해 성능 확인(ROC, AUC)
plt.figure( figsize=(8,8) )

for name, (lineStyle, model) in class_map.items():
    model.fit(X_train, y_train)
    # 에측
    # 예측에 대한 확률로 예측: 0,1 중 1이 될 확률이 0.57% => 1을 더 많이 예측하는 모델
    preds = model.predict_proba(X_test)
    # preds의 type을 y_test에 맞춰줌(Series)
    pred = pd.Series( preds[:,1] )
    # ROC 값 획득
    # return 1.fpr: 거짓양성비/ 2. tpr: 참양성비 / 3. 버리는 변수(결정함수가 사용한 임계값. 지금 필요없지만 받기는 해야 함)
    fpr, tpr, _ = roc_curve( y_test, pred )
    # ROC 드로잉
    # AUC 표시 -> 수치
    auc_score = auc(fpr, tpr)
    print( f'{name} : {auc_score}')
    
    # 선 그리기
    plt.plot(fpr, tpr, lineStyle, linewidth=4, label=name )
    pass

# 시각화 마무리
plt.legend() # 범례 표시
plt.plot( [0,1], [0,1], 'k--' ) # 대각선
plt.show()
```

